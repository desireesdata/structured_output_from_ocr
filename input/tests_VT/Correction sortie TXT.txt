

Correction sortie TXT brut
Export JSON  brut du TXT parfait

Délire à cause du paragraphe qui commence :

d'un projet de loi portant régularisation, ou-
verture et annulation de crédits sur l'exer-
cice 1930-1931 au titre du budget général et
des budgets annexes, p. 1179. — = discuss.
d'un projet de loi relatif aux établissements
dangereux, insalubres ou incommodes, en
qualité de rapporteur, p. 1533, 1535, 1536, 1537.
— = discuss. d'un projet de loi relatif à l'ou-
tillage national, p. 1646, 1707, 1708; son amen-
dement, p. 1707.


Ce qui est généré me pose question sur la manière dont je dois constituer la vérité terrain :
les réptitions (qui n'existent pas) sont assez bien vues car elles donnent du contexte 

en précisant un peu le prompt, j'ai de nouvelles erreurs (ex : bazile gaston est admis)


stats éléments importés (origination, etc)
Reinjecter sortie json dans XML/EAD
génération template XML/EAC
ajout formulaire de contextualisation
	- télécharge liste communes départements
- à développer : si commune; si région; si service décentralisé
- affichage version XML/EAD des vedettes à coté json
- illustration workflow façon ligne de métro
- pouvoir retoucher vedettes
- distance de lev pour détections communes à partir localisaton
- pourcentage de producteur sans notice (avec proposition de génération de notice)
- visualisation écart IR par rapport à un modèle déterminé par une politique d'indexation
- Proposer TOP 5 des notices les plus proches, si oui utiliser ces notices pour l'indeaxtion, sinon Wikidata pour juste obtenir un URI. Sinon, mettre dans un rapport qu'il faudra créer telle notice pour telle autorité
- exports PDF ou HTML rapports
- SAS de traitements, traitement spécifiques par lots

curl 'https://geo.api.gouv.fr/departements/90/communes

Dans la partie application de mon code (dans dekstop-app), il y a des visualisations. Le deuxième tableau, "indicateurs de qualité" indique différentes choses et notamment le nombre de balises origination avec un attribut "authfilenumber"; le nombre de balises origination avec un attribut "normal". C'est une erreur de ma part : je voudrais plutôt indiquer 1) le nombre de balises origination contenant soit une balise geogname avec un attribut "authfilenumber" non vide; 2)  le nombre de balises origination contenant soit une balise corpname avec un attribut "authfilenumber" non vide; 3)  le nombre de balises origination contenant soit une balise persname avec un attribut "authfilenumber" non vide; 4)  le nombre de balises origination contenant soit une balise famname avec un attribut "authfilenumber" non vide

<origination>
	<corpname source="https://francearchives.gouv.fr/agent/224174370"
	authfilenumber=""
	role="producteur | service versant"
	normal="">
	</corpname>
</origination>

/// Control access
<origination id="vEADette-YYYY-MM-DD">
	<corpname | persname | famnname></>
</origination>

<controlaccess id="vEADette-YYYY-MM-DD">
</controlaccess

<function>
</function>

https://api-lannuaire.service-public.fr/api/explore/v2.1/catalog/datasets/api-lannuaire-administration/exports/json

https://api-lannuaire.service-public.fr/api/explore/v2.1/catalog/datasets/api-lannuaire-administration/records?where=nom%20LIKE%20%22Rennes%22&limit=10

https://api-lannuaire.service-public.fr/api/explore/v2.1/catalog/datasets/api-lannuaire-administration/records?where=nom LIKE "Rennes"&limit=10


https://api-lannuaire.service-public.fr/api/explore/v2.1/catalog/datasets/api-lannuaire-administration/records?where=nom%20LIKE%20%22Rennes%22&limit=10

https://api-lannuaire.service-public.fr/api/explore/v2.1/catalog/datasets/api-lannuaire-administration/records?where=nom LIKE%20 'Rennes'&limit=10


https://api-lannuaire.service-public.fr/api/explore/v2.1/catalog/datasets/api-lannuaire-administration/records?where=nom%20LIKE%20%22Cabinet du préfet de la Moselle. - 1377W (1970-1984)%22&limit=10

https://api-lannuaire.service-public.fr/api/explore/v2.1/catalog/datasets/api-lannuaire-administration/records?where=nom%20LIKE%20%22Rennes%22%20AND%20startswith(code_insee_commune,%20%2235%22)



Cabinet du préfet de la Moselle. - 1377W (1970-1984)"


([D|d]épartement(?=[ |,]))
([D|d]énomination)
([R|r]essort)
(Département)
((?<=[\(|,\s])département(?=,))



(Département)|((?<=[\(|,\s])département(?=,))
([D|d]énomination)
([R|r]essort)
(Commune)
(commune[\s|-]siège)
(commune chef-lieu)


Données de sagouin :
(^D[é|e]partement)|(d[é|e]partment)|(d[é|e]partement(?=[,| ]))
(Commune)|([c|C]ommune(?=,))


" title="0 avec " onclick="showPieTooltip(this)" style="background: #FF6384; display: inline-block; margin-right: 2px;"> 0	



A la suite des visualisations, je voudrais ajouter, pour chaque document XML, un bilan :
A) Si le document ne comporte pas de balises origination, ou que la balise origination ne contient aucun noeud textuel, dire "Le document [...] ne semble pas exposer de façon explicite le nom du producteur du fonds; il doit être renseigné".

===>

B) Si le document comporte des balises origination avec un ou des noeuds textuels, mais sans <persname> ni <corpname> ni <famname> ni <geogname>, il faut dire "Le document semble exposer des informations sur le producteur du fonds, mais il faut préciser de quel type il s'agit ! (corpname, persname, famname voire geogname)".



C) Si le document comporte des balises origination avec un ou des noeuds textuels et avec au moins ou un persname, ou un corpname ou un famname ou un geogname mais avec un attribut authfilenumber vide pour ces champs il faut dire : "Le producteur du fonds semble bien renseigné; mais il faut ajouter l'URI".

====> CHERCHER URI via ORIGINATION
(programme existe déjà du coup)

D) Si le document comporte des balises origination non vide avec au moins ou un persname, ou un corpname ou un famname ou un geogname avec une URI indiquée, alors il faut dire "Le producteur du fonds semble bien renseigné."

====> FACULTATIF / A FAIRE PLUS TARD : Vérifier + générer données entrainement

A la suite des visualisations, je voudrais ajouter, pour chaque document XML, un bilan :
Si le document ne comporte pas de balises origination, ou que la balise origination ne contient aucun noeud textuel, dire "Le document [...] ne semble pas exposer de façon explicite le nom du producteur du fonds; il doit être renseigné".
Si le document comporte des balises origination avec un ou des noeuds textuels, mais sans <persname> ni <corpname> ni <famname> ni <geogname>, il faut dire "Le document semble exposer des informations sur le producteur du fonds, mais il faut préciser de quel type il s'agit ! (corpname, persname, famname voire geogname)".
Si le document comporte des balises origination avec un ou des noeuds textuels et avec au moins ou un persname, ou un corpname ou un famname ou un geogname mais avec un attribut authfilenumber vide pour ces champs il faut dire : "Le producteur du fonds semble bien renseigné; mais il faut ajouter l'URI".
Si le document comporte des balises origination non vide avec au moins ou un persname, ou un corpname ou un famname ou un geogname avec une URI indiquée, alors il faut dire "Le producteur du fonds semble bien renseigné."


Je voudrais enrichir dans l'application, le "bilan par document", et notamment à propos des balises <controlaccess> des documents XML importés :

S'il n'y a aucune balise controlaccess dans l'ensemble du document XML, dire : "Aucune balise controlaccess n'est renseignée.".

Sinon s'il y a au moins une balise controlaccess enfant direct de archdesc, et contenant des noeuds textuels, dire : "L'ensemble documentaire décrit bénéficie, grâce à la balise controlaccess, d'un moins un point d'entrée au niveau haut de l'instrument de recherche."
Et si ces noeuds textuels sont balisés soit par persname, soit par corpname soit par geogname soit par famname, soit par subject, exposer les balises existantes "(persname)" si'il y a un persname; "(corpname)" s'il y a un corpname, etc.
Ensuite compter les URI (attributs authfilenumber non vides des balises persname, corpname, geogname, subject, famname) et exposer le pourcentage de balises en ayant une. Seule doivent être prise en compte persname, corpname, geogname, subject, famname : "[X]% des entités disposent d'une URI.". Si c'est 0%, dire "Aucune URI n'est indiquée".

S'il y a des balises controlaccess n'étant pas le ou les enfants de archdesc, mais étant enfant(s) de l'élément <c>, ajouter : 
"L'instrument de recherche semble bénéficier d'une indexation plus fine, au niveau d'unités documentaires décrites". Et, comme précédemment, indiquer le pourcentage de celles qui ont une URI.
Si il n'y a aucune balise controlaccess en plus de celle dans le archdesc, ajouter : "L'instrument de recherche ne bénéficie pas, en revanche, d'une indexation fine au niveau des unités documentaires"


Dans le cas où les documents importés ne sont pas des versions réduites, je voudrais qu'on puisse appliquer le traitement que sur la partie haute. Je voudrais donc ajouter une option ou une alerte lorsqu'on lance le traitement afin de choisir le faire sur une partie ou non

J'ai tenté de compiler mon application Electron avec npm run build, juste pour voir. Le fichier APPImage fait 3,4 Go, ce qui est énorme. J'aimerai, sans que ça impacte le fonctionnement de l'application, que vous :

    Vérifiez les dépendances : Assurez-vous que vous n'incluez pas de dépendances inutiles. Utilisez des outils comme electron-packager ou electron-builder pour empaqueter votre application, car ils permettent de mieux contrôler ce qui est inclus.

    Utilisez electron-builder : C'est un outil puissant pour empaqueter et construire des applications Electron prêtes à être distribuées. Il offre des options pour réduire la taille de l'application finale.

    Exclure les fichiers inutiles : Configurez votre outil de construction pour exclure les fichiers et dossiers qui ne sont pas nécessaires à l'exécution de l'application.

    Optimisez les ressources : Assurez-vous que les images et autres ressources sont optimisées pour le web. Utilisez des outils pour compresser les images.

    Utilisez des scripts de build : Configurez correctement vos scripts de build dans package.json pour utiliser des outils comme webpack pour regrouper et minimiser votre code JavaScript.

    Vérifiez les modules natifs : Si vous utilisez des modules natifs, assurez-vous qu'ils sont compilés pour la bonne architecture et plateforme cible.

    Analysez le contenu de votre application : Après la construction, examinez le contenu du dossier de sortie pour voir ce qui prend de l'espace et identifier les fichiers superflus.
 
 
 ["Voici la proposition n°0 : <30J - Fonds des architectes Boille (1876-2005)>. Au regard du référentiel, la forme autorisée la plus proche de <J - Fonds architectes Boille (-)> est : [Conseil régional de l'ordre des architectes (Occitanie, France)] avec une similarité de 0.34", "Voici la proposition n°1 : <Fonds des architectes Boille>. Au regard du référentiel, la forme autorisée la plus proche de <Fonds architectes Boille> est : [Conseil régional de l'ordre des architectes (Occitanie, France)] avec une similarité de 0.34"]



["Voici la proposition n°0 : <proposition>30J - Fonds des architectes Boille (1876-2005)</proposition>. Au regard du référentiel, la forme autorisée la plus proche de <J - Fonds architectes Boille (-)> est : [Conseil régional de l'ordre des architectes (, France)] avec une similarité de 0.36", "Voici la proposition n°1 : <proposition>Fonds des architectes Boille</proposition>. Au regard du référentiel, la forme autorisée la plus proche de <Fonds architectes Boille> est : [Conseil régional de l'ordre des architectes (, France)] avec une similarité de 0.36"]
début prompting

 Chargement json...
{
  "numero_proposition": 0,
  "producteur_le_plus_probable": "Conseil régional de l'ordre des architectes",
  "forme_autorisee_proche": "Conseil régional de l'ordre des architectes",
  "type_de_la_proposition": "institution",
  "correspondance_entre_producteur_et_forme_autorisee": "OUI"
}mardi 10 juin 2025 16:00 – 17:00
Organisateur : 	
Sébastien CRETIN/ETS/BnF <sebastien.cretin@bnf.fr>
Description : 	Bonjour Joël,

Je te propose de nous retrouver en salle de réunion T1N04.07.

Bien à toi,

Sébastien





Bonjour,

Je suis également étudiant en Archives; j'étudie à l'Ecole Nationale des Chartes en stage pour le projet Mezanno. Je travaille sur mon temps libre sur une application dédié à l'indexation des instruments de recherche (); je ne suis donc pas un expert en IA, mais m'affaire aux problématiques d'indexation automatisés. Je peux vous donner un retour d'expérience en tant que ...

Pour répondre à vos questions : les traitements à déployer pour l'indexation des données dépendent d'abord de leur nature: s'agit-il de documents numérisés ? Déjà OCRisés ? Des données de "qualité", transcrites à la main ? Si les données ont déjà une structure, peut-être que des méthodes "rudimentaires" d'extraction suffiront. Pour des images, Transkribus ...

Ensuite, pour les méthodes d'indexation via IA, il existe en gros plusieurs méthodes, pouvant être couplées :

- les approches "BERT"
- les approches LLM
- les embeddings (représentations vectorielles)
- le LDA (pour les thématiques)
- simple extraction via Regex

Les approches Bert reposent sur l'étiquetage de chaque élément textuel. L'avantage du BERT est d'appliquer une "couche sémantique" au dessus du texte. Pour des besoins d'indexation, on peut donc ensuite "matcher" tous les documents ayant telle ou telle étiquette, par exemple "LOCATION", "PERSON", etc. voire des catégories personnalisées comme "OUVRIERE", "CHEF D'ATELIER", etc. Ici, n'y a donc pas vraiment de risque d'hallucination (dans le sens que le texte d'origine n'est pas modifié) et on peut avoir des catégories "taillés" pour besoins très spécifiques (note: un modèle Bert peut échouer à bien catégoriser une entité, par exemple confondre une institution avec le nom d'un lieu). Le problème principal est que les modèles doivent être entraînés pour être efficaces, et c'est un travail qui implique beaucoup de préparation.

On peut utiliser également les LLM (à l'instar de Chat GPT ou Mistral) pour l'indexation; mais à condition de les utiliser d'une certaine façon, à savoir : la sortie structurée ou la génération structurée. L'idée est d'imposer au modèle un format de sortie (sortie structurée) le forçant ainsi à ne répondre que certains choix parmis ceux soumis. L'avantage ici est de bénéficier d'un modèle de langue déjà très pertinent, sans recourir à un entrainement du modèle. C'est la méthode que j'utilise pour mon application; et qui est utilisée par le projet Mezanno, encore en cours de developpement mais en bonne voie de finalisation. Il existe une version encore plus puissante de cette approche, la génération structurée. Ici, on manipule avec des automates finis (des sortes de graphe de possibilités qu'on aura déterminés en amont) les probabilités de chaque token pouvant être exprimés par un LLM. Pour faire bref, dans la philosophie de la génération ou sortie structurée on utilise la capacité d'analyse d'un LLM et on lui demande de ne répondre qu'avec des choix qu'on lui aura imposés. 

Mais, évidemment ces techniques de pointe peuvent ne pas être forcément utiles, selon la nature des données : en effet des données brutes mais déjà bien structurées peuvent être exploités avec une simple expression régulière (regex).

D'expérience, sur des données peu structurée, il n'y a jamais de solution miracle : il y a toujours des exceptions  
